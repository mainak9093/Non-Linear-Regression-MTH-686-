{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Appendix: Non Linear Regression Project (Corrected for t_orig)**\n",
        "**Author:** Mainak Sarkar | 230619"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading the Data Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.optimize import minimize\n",
        "from scipy.stats import kstest, norm\n",
        "from scipy.linalg import pinv\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Loading data\n",
        "data = pd.read_csv('set-49.dat', sep='\\s+', header=None)\n",
        "print(data.head())\n",
        "\n",
        "# Extract time and observed values\n",
        "t_orig = np.array(data[0], dtype=float)  # Original time (1-60)\n",
        "y1 = np.array(data[1], dtype=float)  # Observed y(t) values\n",
        "n = len(y1)  # Get n from y1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model 1: $y(t) = \\\\alpha_0 + \\\\alpha_1 e^{\\\\beta_1 t} + \\\\alpha_2 e^{\\\\beta_2 t} + \\\\epsilon(t)$\n",
        "\n",
        "## 1.1 Fitting\n",
        "\n",
        "Method changed to Non-Linear Least Squares (NLS) using scipy.optimize for stability with original t values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- NLS implementation for Model 1 ---\n",
        "\n",
        "# Use original time values\n",
        "tt_m1 = t_orig\n",
        "yy_m1 = y1\n",
        "\n",
        "# Model 1 function: p = [a0, a1, b1, a2, b2]\n",
        "def f_model_1(p, t):\n",
        "    a0 = p[0]\n",
        "    a1 = p[1]\n",
        "    b1 = p[2]\n",
        "    a2 = p[3]\n",
        "    b2 = p[4]\n",
        "    return a0 + a1 * np.exp(b1 * t) + a2 * np.exp(b2 * t)\n",
        "\n",
        "# SSE cost function for Model 1\n",
        "def sse_1(p):\n",
        "    yhat = f_model_1(p, tt_m1)\n",
        "    if not np.all(np.isfinite(yhat)):\n",
        "        return 1e10  # Penalize explosions\n",
        "    return np.sum((yy_m1 - yhat)**2)\n",
        "\n",
        "# Initial guesses\n",
        "init_1 = np.array([1.0, 0.2, 0.001, 2.0, -0.3])\n",
        "\n",
        "# Run optimization\n",
        "fit_1 = minimize(sse_1, init_1, method='L-BFGS-B', options={'maxiter': 2000})\n",
        "params_1 = fit_1.x\n",
        "\n",
        "parameter_estimates_1 = params_1\n",
        "alpha0_1 = params_1[0]\n",
        "alpha1_1 = params_1[1]\n",
        "beta1_1 = params_1[2]\n",
        "alpha2_1 = params_1[3]\n",
        "beta2_1 = params_1[4]\n",
        "\n",
        "fitted_values_m1 = f_model_1(params_1, tt_m1)\n",
        "residuals_m1 = yy_m1 - fitted_values_m1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.2 Checking the Model Accuracy for Model 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate model accuracy metrics\n",
        "rmse_1 = np.sqrt(np.mean(residuals_m1**2))\n",
        "rss_1 = np.sum(residuals_m1**2)\n",
        "tss_1 = np.sum((y1 - np.mean(y1))**2)\n",
        "r_squared_1 = 1 - (rss_1 / tss_1)\n",
        "\n",
        "k_1 = 5  # Number of parameters (alpha0, alpha1, beta1, alpha2, beta2)\n",
        "adjusted_r_squared_1 = 1 - ((1 - r_squared_1) * (n - 1) / (n - k_1 - 1))\n",
        "\n",
        "print(f\"RMSE: {rmse_1}\")\n",
        "print(f\"RSS: {rss_1}\")\n",
        "print(f\"TSS: {tss_1}\")\n",
        "print(f\"R-squared: {r_squared_1}\")\n",
        "print(f\"Adjusted R-squared: {adjusted_r_squared_1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.3 Calculating the Jacobian Matrix, FIM and CI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the Jacobian of the model (partial derivatives)\n",
        "def jacobian_1(t, alpha0, alpha1, beta1, alpha2, beta2):\n",
        "    d_alpha0 = 1\n",
        "    d_alpha1 = np.exp(beta1 * t)\n",
        "    d_beta1 = alpha1 * t * np.exp(beta1 * t)\n",
        "    d_alpha2 = np.exp(beta2 * t)\n",
        "    d_beta2 = alpha2 * t * np.exp(beta2 * t)\n",
        "    return np.array([d_alpha0, d_alpha1, d_beta1, d_alpha2, d_beta2])\n",
        "\n",
        "# Fisher Information matrix calculation\n",
        "def fisher_information(t_vec, params, jac_func, sigma2):\n",
        "    n_obs = len(t_vec)\n",
        "    n_params = len(params)\n",
        "    J = np.zeros((n_obs, n_params))\n",
        "    \n",
        "    for i in range(n_obs):\n",
        "        J[i, :] = jac_func(t_vec[i], params[0], params[1], params[2], params[3], params[4])\n",
        "    \n",
        "    # FIM is (1/sigma2) * (J'J)\n",
        "    fisher_matrix = (1 / (n_obs * sigma2)) * (J.T @ J)\n",
        "    \n",
        "    # Regularization (if required)\n",
        "    lambda_reg = 1e-6\n",
        "    fisher_matrix_regularized = fisher_matrix + lambda_reg * np.eye(n_params)\n",
        "    \n",
        "    return fisher_matrix_regularized\n",
        "\n",
        "# Confidence Intervals calculation\n",
        "def confidence_intervals(fisher_matrix, parameter_estimates, alpha=0.05):\n",
        "    # Inverse Fisher Information Matrix (for variance)\n",
        "    fisher_inv = pinv(fisher_matrix)\n",
        "    \n",
        "    # Standard errors\n",
        "    se = np.sqrt(np.diag(fisher_inv))\n",
        "    \n",
        "    # Z value for 95% confidence\n",
        "    z_value = norm.ppf(1 - alpha / 2)\n",
        "    \n",
        "    # Confidence intervals\n",
        "    ci_lower = parameter_estimates - z_value * se\n",
        "    ci_upper = parameter_estimates + z_value * se\n",
        "    \n",
        "    return {'lower': ci_lower, 'upper': ci_upper, 'se': se}\n",
        "\n",
        "sigma2_1 = rss_1 / (n - k_1)\n",
        "\n",
        "# Calculate Fisher Information Matrix for the model parameters\n",
        "fisher_matrix_1 = fisher_information(tt_m1, parameter_estimates_1, jacobian_1, sigma2_1)\n",
        "\n",
        "# Calculate Confidence Intervals\n",
        "ci_1 = confidence_intervals(fisher_matrix_1, parameter_estimates_1)\n",
        "\n",
        "# Print the results\n",
        "print(\"--- Model 1 Results ---\")\n",
        "print(\"Parameters (alpha0, alpha1, beta1, alpha2, beta2):\")\n",
        "print(parameter_estimates_1)\n",
        "print(\"\\nFisher Information Matrix:\")\n",
        "print(fisher_matrix_1)\n",
        "print(\"\\nConfidence Intervals:\")\n",
        "print(f\"Lower: {ci_1['lower']}\")\n",
        "print(f\"Upper: {ci_1['upper']}\")\n",
        "print(f\"Standard Errors: {ci_1['se']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.4 Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up the plotting area with 2x2 subplots\n",
        "fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
        "\n",
        "# Residuals plot\n",
        "axes[0, 0].scatter(t_orig, residuals_m1, color='black', s=30, alpha=0.7)\n",
        "axes[0, 0].axhline(y=0, color='red', linestyle='-')\n",
        "axes[0, 0].set_title('1.6: Residuals vs. Time (Model 1)')\n",
        "axes[0, 0].set_xlabel('Time (Original)')\n",
        "axes[0, 0].set_ylabel('Residuals')\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Q-Q plot of residuals\n",
        "from scipy import stats\n",
        "stats.probplot(residuals_m1, dist=\"norm\", plot=axes[0, 1])\n",
        "axes[0, 1].set_title('1.7(a): Q-Q Plot of Residuals (Model 1)')\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Histogram of residuals\n",
        "axes[1, 0].hist(residuals_m1, bins=10, color='lightblue', edgecolor='black')\n",
        "axes[1, 0].set_title('1.7(b): Histogram of Residuals (Model 1)')\n",
        "axes[1, 0].set_xlabel('Residuals')\n",
        "axes[1, 0].set_ylabel('Frequency')\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Fitted values plot\n",
        "axes[1, 1].plot(t_orig, y1, color='blue', linewidth=2, label='Observed Data')\n",
        "axes[1, 1].plot(t_orig, fitted_values_m1, color='red', linewidth=2, label='Model-1 Fit')\n",
        "axes[1, 1].set_title('1.8: Observed vs. Fitted Data (Model 1)')\n",
        "axes[1, 1].set_xlabel('Time (Original)')\n",
        "axes[1, 1].set_ylabel('Values')\n",
        "axes[1, 1].legend(loc='upper right')\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.5 Applying KS Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standardize residuals\n",
        "standardized_residuals_1 = (residuals_m1 - np.mean(residuals_m1)) / np.std(residuals_m1)\n",
        "\n",
        "# Perform the Kolmogorov-Smirnov test\n",
        "ks_test_1 = kstest(standardized_residuals_1, 'norm', args=(0, 1))\n",
        "\n",
        "# Display KS test results\n",
        "print(\"--- Model 1 KS Test ---\")\n",
        "print(f\"KS Test Statistic: {ks_test_1.statistic}\")\n",
        "print(f\"KS Test p-value: {ks_test_1.pvalue}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Model 2: $y(t) = \\\\frac{\\\\beta_0 + \\\\beta_1 t}{\\\\alpha_0 + \\\\alpha_1 t} + \\\\epsilon(t)$\n",
        "\n",
        "No changes needed, this model already uses `t_orig`\n",
        "\n",
        "## 2.1 Fitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and align t and y again\n",
        "tt = t_orig\n",
        "yy = y1\n",
        "assert len(tt) == len(yy), \"Length mismatch between tt and yy\"\n",
        "\n",
        "# Define model [a0, a1, b0, b1]\n",
        "def f_model_2(p, t):\n",
        "    a0 = p[0]\n",
        "    a1 = p[1]\n",
        "    b0 = p[2]\n",
        "    b1 = p[3]\n",
        "    denom = b0 + b1 * t\n",
        "    \n",
        "    # Avoid division by zero\n",
        "    if np.any(np.abs(denom) < 1e-8):\n",
        "        return np.full_like(t, np.inf, dtype=float)\n",
        "    \n",
        "    return (a0 + a1 * t) / denom\n",
        "\n",
        "# Define SSE cost function\n",
        "def sse_2(p):\n",
        "    yhat = f_model_2(p, tt)\n",
        "    if not np.all(np.isfinite(yhat)):\n",
        "        return 1e10  # Penalize bad parameters\n",
        "    return np.sum((yy - yhat)**2)\n",
        "\n",
        "# Initial guess from simple linear fit\n",
        "fit_poly_lin = np.polyfit(tt, yy, 1)\n",
        "a0_init = fit_poly_lin[1]  # Intercept\n",
        "a1_init = fit_poly_lin[0]  # Slope\n",
        "b0_init = 1.0  # Guess\n",
        "b1_init = 0.1  # Guess\n",
        "init_2 = np.array([a0_init, a1_init, b0_init, b1_init])\n",
        "\n",
        "# Use L-BFGS-B with bounds\n",
        "fit_2 = minimize(sse_2, init_2, method='L-BFGS-B',\n",
        "                bounds=[(-10, 10), (-10, 10), (0.01, 20), (-10, 20)],\n",
        "                options={'maxiter': 2000})\n",
        "\n",
        "params_2 = fit_2.x\n",
        "\n",
        "a0_2 = params_2[0]\n",
        "a1_2 = params_2[1]\n",
        "b0_2 = params_2[2]\n",
        "b1_2 = params_2[3]\n",
        "\n",
        "# Final predictions and residuals\n",
        "fitted_values_2 = f_model_2(params_2, tt)\n",
        "residuals_2 = yy - fitted_values_2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.2 Checking the Model Accuracy for Model 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate model accuracy metrics\n",
        "rmse_2 = np.sqrt(np.mean(residuals_2**2))\n",
        "rss_2 = np.sum(residuals_2**2)\n",
        "tss_2 = np.sum((yy - np.mean(yy))**2)\n",
        "r_squared_2 = 1 - (rss_2 / tss_2)\n",
        "\n",
        "k_2 = 4  # Number of parameters (a0, a1, b0, b1)\n",
        "adjusted_r_squared_2 = 1 - ((1 - r_squared_2) * (n - 1) / (n - k_2 - 1))\n",
        "\n",
        "print(f\"RMSE: {rmse_2}\")\n",
        "print(f\"RSS: {rss_2}\")\n",
        "print(f\"TSS: {tss_2}\")\n",
        "print(f\"R-squared: {r_squared_2}\")\n",
        "print(f\"Adjusted R-squared: {adjusted_r_squared_2}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.3 Calculating the Jacobian Matrix, FIM and CI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the Jacobian for Model 2\n",
        "def jacobian_2(t, a0, a1, b0, b1):\n",
        "    denom = b0 + b1 * t\n",
        "    d_a0 = 1 / denom\n",
        "    d_a1 = t / denom\n",
        "    d_b0 = -(a0 + a1 * t) / (denom**2)\n",
        "    d_b1 = -t * (a0 + a1 * t) / (denom**2)\n",
        "    return np.array([d_a0, d_a1, d_b0, d_b1])\n",
        "\n",
        "# Fisher Information matrix calculation (4-param version)\n",
        "def fisher_information_4param(t_vec, params, jac_func, sigma2):\n",
        "    n_obs = len(t_vec)\n",
        "    n_params = len(params)\n",
        "    J = np.zeros((n_obs, n_params))\n",
        "    \n",
        "    for i in range(n_obs):\n",
        "        J[i, :] = jac_func(t_vec[i], params[0], params[1], params[2], params[3])\n",
        "    \n",
        "    fisher_matrix = (1 / (n_obs * sigma2)) * (J.T @ J)\n",
        "    \n",
        "    lambda_reg = 1e-6\n",
        "    fisher_matrix_regularized = fisher_matrix + lambda_reg * np.eye(n_params)\n",
        "    \n",
        "    return fisher_matrix_regularized\n",
        "\n",
        "# Confidence Intervals calculation (4-param version)\n",
        "def confidence_intervals_4param(fisher_matrix, parameter_estimates, alpha=0.05):\n",
        "    fisher_inv = pinv(fisher_matrix)\n",
        "    se = np.sqrt(np.diag(fisher_inv))\n",
        "    z_value = norm.ppf(1 - alpha / 2)\n",
        "    ci_lower = parameter_estimates - z_value * se\n",
        "    ci_upper = parameter_estimates + z_value * se\n",
        "    return {'lower': ci_lower, 'upper': ci_upper, 'se': se}\n",
        "\n",
        "# Calculate sigma^2 estimate\n",
        "sigma2_2 = rss_2 / (n - k_2)\n",
        "\n",
        "# Calculate Fisher Information Matrix\n",
        "fisher_matrix_2 = fisher_information_4param(tt, params_2, jacobian_2, sigma2_2)\n",
        "\n",
        "# Calculate Confidence Intervals\n",
        "ci_2 = confidence_intervals_4param(fisher_matrix_2, params_2)\n",
        "\n",
        "# Print the results\n",
        "print(\"--- Model 2 Results ---\")\n",
        "print(\"Parameters (a0, a1, b0, b1):\")\n",
        "print(params_2)\n",
        "print(\"\\nFisher Information Matrix:\")\n",
        "print(fisher_matrix_2)\n",
        "print(\"\\nConfidence Intervals:\")\n",
        "print(f\"Lower: {ci_2['lower']}\")\n",
        "print(f\"Upper: {ci_2['upper']}\")\n",
        "print(f\"Standard Errors: {ci_2['se']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.4 Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
        "\n",
        "# Residuals plot\n",
        "axes[0, 0].scatter(tt, residuals_2, color='black', s=30, alpha=0.7)\n",
        "axes[0, 0].axhline(y=0, color='red', linestyle='-')\n",
        "axes[0, 0].set_title('2.6: Residuals vs. Time (Model 2)')\n",
        "axes[0, 0].set_xlabel('Time (Original)')\n",
        "axes[0, 0].set_ylabel('Residuals')\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Q-Q plot of residuals\n",
        "stats.probplot(residuals_2, dist=\"norm\", plot=axes[0, 1])\n",
        "axes[0, 1].set_title('2.7(a): Q-Q Plot of Residuals (Model 2)')\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Histogram of residuals\n",
        "axes[1, 0].hist(residuals_2, bins=10, color='lightblue', edgecolor='black')\n",
        "axes[1, 0].set_title('2.7(b): Histogram of Residuals (Model 2)')\n",
        "axes[1, 0].set_xlabel('Residuals')\n",
        "axes[1, 0].set_ylabel('Frequency')\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Fitted values plot\n",
        "tt_ord = np.argsort(tt)\n",
        "axes[1, 1].plot(tt[tt_ord], yy[tt_ord], color='blue', linewidth=2, label='Observed Data')\n",
        "axes[1, 1].plot(tt[tt_ord], fitted_values_2[tt_ord], color='red', linewidth=2, label='Model-2 Fit')\n",
        "axes[1, 1].set_title('2.8: Observed vs. Fitted Data (Model 2)')\n",
        "axes[1, 1].set_xlabel('Time (Original)')\n",
        "axes[1, 1].set_ylabel('Values')\n",
        "axes[1, 1].legend(loc='upper right')\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.5 Applying KS Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standardize residuals\n",
        "standardized_residuals_2 = (residuals_2 - np.mean(residuals_2)) / np.std(residuals_2)\n",
        "\n",
        "# Perform the Kolmogorov-Smirnov test\n",
        "ks_test_2 = kstest(standardized_residuals_2, 'norm', args=(0, 1))\n",
        "\n",
        "# Display KS test results\n",
        "print(\"--- Model 2 KS Test ---\")\n",
        "print(f\"KS Test Statistic: {ks_test_2.statistic}\")\n",
        "print(f\"KS Test p-value: {ks_test_2.pvalue}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Model 3: $y(t) = \\\\beta_0 + \\\\beta_1 t + \\\\beta_2 t^2 + \\\\beta_3 t^3 + \\\\beta_4 t^4 + \\\\epsilon(t)$\n",
        "\n",
        "Updated to use `t_orig` instead of rescaled t\n",
        "\n",
        "## 3.1 Fitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fit a 4th-degree polynomial regression model using ORIGINAL t\n",
        "# Create design matrix\n",
        "X = np.column_stack([np.ones(len(t_orig)), t_orig, t_orig**2, t_orig**3, t_orig**4])\n",
        "\n",
        "# Fit using least squares\n",
        "parameter_estimates_3 = np.linalg.lstsq(X, y1, rcond=None)[0]\n",
        "\n",
        "# Calculate fitted values and residuals\n",
        "fitted_values_3 = X @ parameter_estimates_3\n",
        "residuals_3 = y1 - fitted_values_3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.2 Checking the Model Accuracy for Model 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate model accuracy metrics\n",
        "rmse_3 = np.sqrt(np.mean(residuals_3**2))\n",
        "rss_3 = np.sum(residuals_3**2)\n",
        "tss_3 = np.sum((y1 - np.mean(y1))**2)\n",
        "r_squared_3 = 1 - (rss_3 / tss_3)\n",
        "\n",
        "k_3 = 5  # Number of parameters (beta0, beta1, beta2, beta3, beta4)\n",
        "adjusted_r_squared_3 = 1 - ((1 - r_squared_3) * (n - 1) / (n - k_3 - 1))\n",
        "\n",
        "print(f\"RMSE: {rmse_3}\")\n",
        "print(f\"RSS: {rss_3}\")\n",
        "print(f\"TSS: {tss_3}\")\n",
        "print(f\"R-squared: {r_squared_3}\")\n",
        "print(f\"Adjusted R-squared: {adjusted_r_squared_3}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.3 Calculating the Jacobian Matrix, FIM and CI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the Jacobian of the model\n",
        "def jacobian_3(t, beta0, beta1, beta2, beta3, beta4):\n",
        "    d_beta0 = 1\n",
        "    d_beta1 = t\n",
        "    d_beta2 = t**2\n",
        "    d_beta3 = t**3\n",
        "    d_beta4 = t**4\n",
        "    return np.array([d_beta0, d_beta1, d_beta2, d_beta3, d_beta4])\n",
        "\n",
        "# Fisher Information matrix calculation (5-param version)\n",
        "def fisher_information_5param(t_vec, params, jac_func, sigma2):\n",
        "    n_obs = len(t_vec)\n",
        "    n_params = len(params)\n",
        "    J = np.zeros((n_obs, n_params))\n",
        "    \n",
        "    for i in range(n_obs):\n",
        "        J[i, :] = jac_func(t_vec[i], params[0], params[1], params[2], params[3], params[4])\n",
        "    \n",
        "    fisher_matrix = (1 / (n_obs * sigma2)) * (J.T @ J)\n",
        "    \n",
        "    lambda_reg = 1e-6\n",
        "    fisher_matrix_regularized = fisher_matrix + lambda_reg * np.eye(n_params)\n",
        "    \n",
        "    return fisher_matrix_regularized\n",
        "\n",
        "# Confidence Intervals calculation (5-param version)\n",
        "def confidence_intervals_5param(fisher_matrix, parameter_estimates, alpha=0.05):\n",
        "    fisher_inv = pinv(fisher_matrix)\n",
        "    se = np.sqrt(np.diag(fisher_inv))\n",
        "    z_value = norm.ppf(1 - alpha / 2)\n",
        "    ci_lower = parameter_estimates - z_value * se\n",
        "    ci_upper = parameter_estimates + z_value * se\n",
        "    return {'lower': ci_lower, 'upper': ci_upper, 'se': se}\n",
        "\n",
        "beta0 = parameter_estimates_3[0]\n",
        "beta1 = parameter_estimates_3[1]\n",
        "beta2 = parameter_estimates_3[2]\n",
        "beta3 = parameter_estimates_3[3]\n",
        "beta4 = parameter_estimates_3[4]\n",
        "\n",
        "# Calculate sigma^2 estimate\n",
        "sigma2_3 = rss_3 / (n - k_3)\n",
        "\n",
        "# Calculate Fisher Information Matrix using t_orig\n",
        "fisher_matrix_3 = fisher_information_5param(t_orig, parameter_estimates_3, jacobian_3, sigma2_3)\n",
        "\n",
        "# Calculate Confidence Intervals\n",
        "ci_3 = confidence_intervals_5param(fisher_matrix_3, parameter_estimates_3)\n",
        "\n",
        "# Print the results\n",
        "print(\"--- Model 3 Results ---\")\n",
        "print(\"Parameters (beta0, beta1, beta2, beta3, beta4):\")\n",
        "print(parameter_estimates_3)\n",
        "print(\"\\nFisher Information Matrix:\")\n",
        "print(fisher_matrix_3)\n",
        "print(\"\\nConfidence Intervals:\")\n",
        "print(f\"Lower: {ci_3['lower']}\")\n",
        "print(f\"Upper: {ci_3['upper']}\")\n",
        "print(f\"Standard Errors: {ci_3['se']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.4 Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
        "\n",
        "# Residuals Plot for Model 3\n",
        "axes[0, 0].scatter(t_orig, residuals_3, color='black', s=30, alpha=0.7)\n",
        "axes[0, 0].axhline(y=0, color='red', linestyle='-')\n",
        "axes[0, 0].set_title('3.6: Residuals vs. Time (Model 3)')\n",
        "axes[0, 0].set_xlabel('Time (Original)')\n",
        "axes[0, 0].set_ylabel('Residuals')\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Q-Q Plot for Model 3 Residuals\n",
        "stats.probplot(residuals_3, dist=\"norm\", plot=axes[0, 1])\n",
        "axes[0, 1].set_title('3.7(a): Q-Q Plot of Residuals (Model 3)')\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Histogram of Residuals for Model 3\n",
        "axes[1, 0].hist(residuals_3, bins=10, color='lightblue', edgecolor='black')\n",
        "axes[1, 0].set_title('3.7(b): Histogram of Residuals (Model 3)')\n",
        "axes[1, 0].set_xlabel('Residuals')\n",
        "axes[1, 0].set_ylabel('Frequency')\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Observed vs. Fitted Data Plot for Model 3\n",
        "axes[1, 1].plot(t_orig, y1, color='blue', linewidth=2, label='Observed Data')\n",
        "axes[1, 1].plot(t_orig, fitted_values_3, color='red', linewidth=2, label='Model-3 Fit')\n",
        "axes[1, 1].set_title('3.8: Observed vs. Fitted Data (Model 3)')\n",
        "axes[1, 1].set_xlabel('Time (Original)')\n",
        "axes[1, 1].set_ylabel('Values')\n",
        "axes[1, 1].legend(loc='upper right')\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.5 Applying KS Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standardize residuals\n",
        "standardized_residuals_3 = (residuals_3 - np.mean(residuals_3)) / np.std(residuals_3)\n",
        "\n",
        "# Perform the Kolmogorov-Smirnov test\n",
        "ks_test_3 = kstest(standardized_residuals_3, 'norm', args=(0, 1))\n",
        "\n",
        "# Display KS test results\n",
        "print(\"--- Model 3 KS Test ---\")\n",
        "print(f\"KS Test Statistic: {ks_test_3.statistic}\")\n",
        "print(f\"KS Test p-value: {ks_test_3.pvalue}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# 4.0 Model Comparison\n",
        "\n",
        "This section provides a summary of all three models to help determine the 'best' fit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a comparison table\n",
        "model_names = [\"Model 1 (Exponential)\", \"Model 2 (Rational [1/1])\", \"Model 3 (Poly 4th deg)\"]\n",
        "rss_values = [rss_1, rss_2, rss_3]\n",
        "r_squared_values = [r_squared_1, r_squared_2, r_squared_3]\n",
        "adj_r_squared_values = [adjusted_r_squared_1, adjusted_r_squared_2, adjusted_r_squared_3]\n",
        "ks_p_values = [ks_test_1.pvalue, ks_test_2.pvalue, ks_test_3.pvalue]\n",
        "\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Model': model_names,\n",
        "    'RSS': rss_values,\n",
        "    'R_Squared': r_squared_values,\n",
        "    'Adjusted_R_Squared': adj_r_squared_values,\n",
        "    'KS_Test_p_value': ks_p_values\n",
        "})\n",
        "\n",
        "print(\"\\n## Model Fit Comparison\\n\")\n",
        "print(comparison_df.to_string(index=False))\n",
        "\n",
        "print(\"\\n### Interpretation Guide\\n\")\n",
        "print(\"* **RSS (Residual Sum of Squares):** Lower is better.\")\n",
        "print(\"* **Adjusted R-Squared:** Higher is better (adjusts for the number of parameters).\")\n",
        "print(\"* **KS Test p-value:** A value < 0.05 suggests the residuals are *not* normally distributed, which violates a model assumption.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}